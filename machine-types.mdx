---
title: "Machine Types"
description: "Available computational resources for executing your workloads"
---

## Overview

Lyceum Cloud provides various machine types optimized for different computational workloads. The platform offers both CPU and GPU configurations to match your specific requirements.

## Execution Types

When starting an execution through the API, you can specify the `execution_type` parameter:

```json
{
  "code": "your_python_code",
  "execution_type": "cpu"  // or "gpu", "auto", "a100"
}
```

### Available Options
- **cpu**: Standard CPU execution environment
- **gpu**: GPU-accelerated execution
- **auto**: Automatic selection based on your code
- **a100**: High-performance A100 GPU execution

## Automatic Resource Selection

The platform can automatically select appropriate resources by analyzing your code:

```python
# The platform detects ML frameworks and selects GPU automatically
import torch
import tensorflow as tf

# Your deep learning code here
model = torch.nn.Sequential(...)
```

When using `execution_type: "auto"`, the system will:
- Detect imported packages and frameworks
- Estimate resource requirements
- Select the most appropriate machine type
- Optimize for cost-effectiveness

## Resource Monitoring

Monitor resource usage during execution to optimize your selection:

```python
import psutil

# Check CPU usage
cpu_percent = psutil.cpu_percent(interval=1)
print(f"CPU Usage: {cpu_percent}%")

# Check memory usage
memory = psutil.virtual_memory()
print(f"Memory Usage: {memory.percent}%")

# Check if GPU is available
try:
    import torch
    if torch.cuda.is_available():
        print(f"GPU Available: {torch.cuda.get_device_name()}")
        print(f"GPU Memory: {torch.cuda.mem_get_info()}")
except ImportError:
    print("PyTorch not installed")
```

## Choosing the Right Type

### Use CPU for:
- Data processing and analysis with pandas/numpy
- Web scraping and API calls
- File processing and transformations
- Statistical computing
- General Python scripts

### Use GPU for:
- Deep learning model training
- Computer vision tasks
- Natural language processing with transformers
- Parallel computing with CUDA
- Large-scale matrix operations

## Docker Execution

For containerized workloads, use the Docker execution endpoint:

```bash
curl -X POST https://api.lyceum.technology/api/v2/external/execution/image/start \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "docker_image_ref": "python:3.9",
    "docker_run_cmd": ["python", "script.py"],
    "execution_type": "cpu"
  }'
```

## Timeout Settings

Configure execution timeouts (1-600 seconds) to prevent runaway processes:

```json
{
  "code": "your_code",
  "timeout": 300,  // 5 minutes
  "execution_type": "cpu"
}
```

## Best Practices

### Start Small
Begin with standard CPU execution and upgrade only if needed:

```python
# Start with CPU
execution_type = "cpu"

# Monitor performance
# If GPU is needed, switch to:
execution_type = "gpu"
```

### Profile Your Code
Test locally to understand resource requirements:

```python
import time
import tracemalloc

# Start memory profiling
tracemalloc.start()

# Your code here
start_time = time.time()
result = your_function()
end_time = time.time()

# Get memory usage
current, peak = tracemalloc.get_traced_memory()
tracemalloc.stop()

print(f"Execution time: {end_time - start_time:.2f} seconds")
print(f"Peak memory usage: {peak / 1024 / 1024:.1f} MB")
```

### Optimize Usage
- Use batch processing for multiple small tasks
- Clean up resources after use
- Monitor execution logs for performance insights

## Environment Variables

Access execution environment information:

```python
import os

# Check execution type
execution_type = os.environ.get('LYCEUM_EXECUTION_TYPE', 'unknown')
print(f"Running on: {execution_type}")

# Check available resources
if os.environ.get('CUDA_VISIBLE_DEVICES'):
    print("GPU execution environment detected")
```

## Storage Integration

All machine types have access to your cloud storage:

```python
# Files are available at the storage path
storage_path = os.environ.get('LYCEUM_STORAGE_PATH', '/lyceum/storage/')

# Access your uploaded files
import pandas as pd
df = pd.read_csv(f"{storage_path}/data/input.csv")

# Save results
df.to_csv(f"{storage_path}/outputs/results.csv")
```

<Note>
For current pricing and detailed specifications, check the dashboard or contact support. Machine type availability may vary based on demand.
</Note>